# ğŸš€ TaxoClass ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

## ğŸ“¦ ì„¤ì¹˜

### 1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
cd taxoclass
pip install -r requirements.txt
```

### 2. ì„¤ì¹˜ í™•ì¸

```bash
python quick_test.py
```

## âš™ï¸ ì„¤ì •

### ë°ì´í„° ê²½ë¡œ ì„¤ì •

`config.py` íŒŒì¼ì„ ì—´ê³  ë°ì´í„° ê²½ë¡œë¥¼ í™•ì¸/ìˆ˜ì •í•˜ì„¸ìš”:

```python
DATA_DIR = "../Amazon_products"
```

í˜„ì¬ ì„¤ì •:
- Classes: `Amazon_products/classes.txt`
- Hierarchy: `Amazon_products/class_hierarchy.txt`
- Train: `Amazon_products/train/train_corpus.txt`
- Test: `Amazon_products/test/test_corpus.txt`

## ğŸƒ ì‹¤í–‰

### ë°©ë²• 1: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```bash
python main.py
```

ë˜ëŠ”:

```bash
./run.sh
```

### ë°©ë²• 2: ë‹¨ê³„ë³„ ì‹¤í–‰

```bash
# ì˜ˆì œ ì½”ë“œ ì‹¤í–‰ (ê³„ì¸µ êµ¬ì¡° íƒìƒ‰)
python example_usage.py
```

## ğŸ“Š ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„

| ë‹¨ê³„ | ì‹œê°„ (CPU) | ì‹œê°„ (GPU) |
|------|-----------|-----------|
| Stage 1: Similarity | ~2ì‹œê°„ | ~30ë¶„ |
| Stage 2: Core Mining | ~10ë¶„ | ~10ë¶„ |
| Stage 3: Training | ~4ì‹œê°„ | ~1ì‹œê°„ |
| Stage 4: Self-Training | ~6ì‹œê°„ | ~1.5ì‹œê°„ |
| **ì´í•©** | **~12ì‹œê°„** | **~3ì‹œê°„** |

*ì•½ 29,000ê°œ ë¬¸ì„œ, 532ê°œ í´ë˜ìŠ¤ ê¸°ì¤€

## âš¡ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì‘ì€ ë°ì´í„°ì…‹)

ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ `config.py`ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”:

```python
# í›ˆë ¨ ì—í¬í¬ ì¤„ì´ê¸°
NUM_EPOCHS = 3

# ë°°ì¹˜ ì‚¬ì´ì¦ˆ ëŠ˜ë¦¬ê¸° (GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œ ê²½ìš°)
BATCH_SIZE = 64

# Self-training ë°˜ë³µ ì¤„ì´ê¸°
SELF_TRAIN_ITERATIONS = 2
```

ë˜ëŠ” `main.py`ì—ì„œ:

```python
# Self-training ê±´ë„ˆë›°ê¸°
run_self_training = False

# ë¹ ë¥¸ ìœ ì‚¬ë„ ê³„ì‚° ì‚¬ìš©
use_fast_similarity = True
```

## ğŸ“ ì¶œë ¥ íŒŒì¼

ì‹¤í–‰ í›„ ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤:

```
taxoclass/
â”œâ”€â”€ cache/
â”‚   â””â”€â”€ similarity_matrix_*.pkl      # ìºì‹œëœ ìœ ì‚¬ë„ í–‰ë ¬
â”œâ”€â”€ saved_models/
â”‚   â”œâ”€â”€ best_model.pt                # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
â”‚   â”œâ”€â”€ checkpoint_epoch_*.pt        # ì²´í¬í¬ì¸íŠ¸
â”‚   â””â”€â”€ self_train_iter_*.pt         # Self-training ëª¨ë¸
â””â”€â”€ outputs/
    â””â”€â”€ metrics.txt                   # í‰ê°€ ê²°ê³¼
```

## ğŸ› ë¬¸ì œ í•´ê²°

### CUDA Out of Memory

```python
# config.py ìˆ˜ì •
BATCH_SIZE = 16
SIMILARITY_BATCH_SIZE = 8
```

### ëŠë¦° ì‹¤í–‰ ì†ë„

```python
# main.py ìˆ˜ì •
use_fast_similarity = True  # ë¹ ë¥¸ ìœ ì‚¬ë„ ê³„ì‚° ì‚¬ìš©
run_self_training = False   # Self-training ê±´ë„ˆë›°ê¸°
```

### ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ

```bash
# ë°ì´í„° ê²½ë¡œ í™•ì¸
ls ../Amazon_products/

# config.pyì—ì„œ DATA_DIR ê²½ë¡œ ìˆ˜ì •
```

## ğŸ“ˆ ê²°ê³¼ í™•ì¸

### 1. ì½˜ì†” ì¶œë ¥

ì‹¤í–‰ ì¤‘ ê° ë‹¨ê³„ì˜ ì§„í–‰ ìƒí™©ê³¼ ê²°ê³¼ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.

### 2. ë©”íŠ¸ë¦­ íŒŒì¼

```bash
cat outputs/metrics.txt
```

### 3. ì €ì¥ëœ ëª¨ë¸ ì‚¬ìš©

```python
from models.classifier import TaxoClassifier
import torch

model = TaxoClassifier(num_classes=532)
checkpoint = torch.load("saved_models/best_model.pt")
model.load_state_dict(checkpoint['model_state_dict'])
```

## ğŸ’¡ íŒ

### GPU ë©”ëª¨ë¦¬ ìµœì í™”

1. **ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ… í™œì„±í™”**
2. **Mixed Precision Training ì‚¬ìš©**
3. **ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¤„ì´ê¸°**

### ì„±ëŠ¥ í–¥ìƒ

1. **ë” ë§ì€ ì—í¬í¬ í›ˆë ¨**
2. **Learning rate íŠœë‹**
3. **GNN ë ˆì´ì–´ ìˆ˜ ì¦ê°€**

### ë””ë²„ê¹…

```python
# config.py
DEVICE = "cpu"  # CPUë¡œ í…ŒìŠ¤íŠ¸
NUM_EPOCHS = 1  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
```

## ğŸ“ ë„ì›€ë§

ë¬¸ì œê°€ ë°œìƒí•˜ë©´:

1. `quick_test.py` ì‹¤í–‰í•˜ì—¬ ì„¤ì¹˜ í™•ì¸
2. `example_usage.py` ì‹¤í–‰í•˜ì—¬ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
3. ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
4. `config.py` ì„¤ì • í™•ì¸

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. âœ… ì„¤ì¹˜ ì™„ë£Œ
2. âœ… ë°ì´í„° í™•ì¸
3. âœ… ê¸°ë³¸ ì‹¤í–‰
4. ğŸ“Š ê²°ê³¼ ë¶„ì„
5. ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
6. ğŸš€ í”„ë¡œë•ì…˜ ë°°í¬

---

**Happy Classifying! ğŸ‰**

