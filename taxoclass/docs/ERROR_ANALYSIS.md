# Stage 4 ì—ëŸ¬ ë¶„ì„ ë° ìˆ˜ì •

## âœ… ìˆ˜ì • ì™„ë£Œ: edge_index ì—ëŸ¬

### ë°œìƒí•œ ì—ëŸ¬
```
ValueError: edge_index must be provided either as argument or registered buffer
```

### ì›ì¸
- Stage 3ì„ ê±´ë„ˆë›°ê³  ëª¨ë¸ì„ ë¡œë“œí•  ë•Œ, `edge_index`ê°€ ëª¨ë¸ì˜ ë²„í¼ë¡œ ë“±ë¡ë˜ì§€ ì•ŠìŒ
- DataParallel í™˜ê²½ì—ì„œ `edge_index` ì—†ì´ forward passë¥¼ ì‹œë„í•˜ì—¬ ì‹¤íŒ¨

### í•´ê²° ë°©ë²•
**main.py ìˆ˜ì •ì‚¬í•­:**
1. Stage 3ì„ ê±´ë„ˆë›¸ ë•Œ ëª¨ë¸ ë¡œë“œ í›„ `edge_index`ë¥¼ ë²„í¼ë¡œ ë“±ë¡
2. `model.register_buffer('edge_index', edge_index)` ì¶”ê°€
3. DataParallel ë˜í•‘ì€ SelfTrainerì—ê²Œ ìœ„ì„ (ì´ì¤‘ ë˜í•‘ ë°©ì§€)

```python
# main.py Line ~425
model.register_buffer('edge_index', edge_index)ã…‡
model = model.to(main_device)
# DataParallel ë˜í•‘ì€ SelfTrainerì—ì„œ ì²˜ë¦¬
```

---

## âš ï¸ ì¶”ê°€ ë°œìƒ ê°€ëŠ¥í•œ ì—ëŸ¬ ë¶„ì„

### 1. ë©”ëª¨ë¦¬ ë¶€ì¡± ì—ëŸ¬ (OOM - Out of Memory)

**ë°œìƒ ê°€ëŠ¥ ìƒí™©:**
- Self-training ì‹œ ì „ì²´ ë°ì´í„°ì…‹(49,145ê°œ ë¬¸ì„œ)ì— ëŒ€í•´ prediction ìƒì„±
- Unlabeled datasetì´ ë„ˆë¬´ í¬ë©´ ë©”ëª¨ë¦¬ ë¶€ì¡± ë°œìƒ ê°€ëŠ¥

**ì¦ìƒ:**
```
RuntimeError: CUDA out of memory
torch.cuda.OutOfMemoryError
```

**ì˜ˆë°© ì¡°ì¹˜:**
- `config.py`ì—ì„œ batch size ì¡°ì •:
  ```python
  BATCH_SIZE = 16  # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ 8ë¡œ ê°ì†Œ
  EVAL_BATCH_SIZE = 128  # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ 64ë¡œ ê°ì†Œ
  ```
- Gradient accumulation ì‚¬ìš© (ì´ë¯¸ ì„¤ì •ë¨):
  ```python
  GRADIENT_ACCUMULATION_STEPS = 4
  ```

**ë°œìƒ ì‹œ ëŒ€ì²˜:**
1. Batch sizeë¥¼ ì¤„ì´ê¸°: `BATCH_SIZE = 8`, `EVAL_BATCH_SIZE = 64`
2. Mixed precision í™œì„±í™” í™•ì¸: `USE_MIXED_PRECISION = True` (ì´ë¯¸ ì„¤ì •ë¨)
3. GPU ìºì‹œ ì •ë¦¬: `torch.cuda.empty_cache()` í˜¸ì¶œ

---

### 2. DataParallelê³¼ ê´€ë ¨ëœ ì—ëŸ¬

**ë°œìƒ ê°€ëŠ¥ ìƒí™©:**
- ëª¨ë¸ì´ ì´ë¯¸ DataParallelë¡œ ë˜í•‘ë˜ì–´ ìˆëŠ”ë° ë‹¤ì‹œ ë˜í•‘í•˜ë ¤ê³  í•  ë•Œ
- DataParallel ëª¨ë¸ì—ì„œ module ì ‘ê·¼ ì‹œ ì—ëŸ¬

**ì¦ìƒ:**
```
AttributeError: 'DataParallel' object has no attribute 'xxx'
RuntimeError: module must have its parameters and buffers on device cuda:0
```

**ì˜ˆë°© ì¡°ì¹˜ (ì´ë¯¸ ì ìš©ë¨):**
```python
# SelfTrainerì—ì„œ ì´ì¤‘ ë˜í•‘ ë°©ì§€
if use_multi_gpu and torch.cuda.device_count() > 1 and not isinstance(self.model, torch.nn.DataParallel):
    self.model = torch.nn.DataParallel(self.model)

# ì‹¤ì œ ëª¨ë¸ì— ì ‘ê·¼í•  ë•Œ
actual_model = self.model.module if hasattr(self.model, 'module') else self.model
```

**ë°œìƒ ì‹œ ëŒ€ì²˜:**
- ëª¨ë¸ ì €ì¥ ì‹œ: `model.module.state_dict()` ì‚¬ìš©
- ëª¨ë¸ ë¡œë“œ ì‹œ: unwrapped modelì— ë¡œë“œ

---

### 3. Target Distribution ê´€ë ¨ ìˆ˜ì¹˜ ì—ëŸ¬

**ë°œìƒ ê°€ëŠ¥ ìƒí™©:**
- Temperature sharpening ì‹œ ìˆ˜ì¹˜ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜ ì»¤ì§ˆ ë•Œ
- Log ê³„ì‚° ì‹œ 0ì´ ì…ë ¥ë˜ì–´ `-inf` ë°œìƒ

**ì¦ìƒ:**
```
RuntimeError: Function 'LogBackward' returned nan values
RuntimeError: CUDA error: device-side assert triggered
```

**ì˜ˆë°© ì¡°ì¹˜ (ì´ë¯¸ ì ìš©ë¨):**
```python
# self_training.pyì—ì„œ
eps = 1e-10  # Small epsilon for numerical stability
log_predictions = torch.log(predictions + eps)
log_target = torch.log(target_distribution + eps)
```

**ì„¤ì • ì¡°ì • ê°€ëŠ¥:**
```python
# config.py
SELF_TRAIN_TEMPERATURE = 2.0  # ë„ˆë¬´ ì‘ìœ¼ë©´ (< 1) ë¶ˆì•ˆì •
SELF_TRAIN_THRESHOLD = 0.8  # ë„ˆë¬´ ë†’ìœ¼ë©´ í•™ìŠµ ë°ì´í„° ë¶€ì¡±
```

---

### 4. í•™ìŠµ ì¤‘ Gradient Explosion/Vanishing

**ë°œìƒ ê°€ëŠ¥ ìƒí™©:**
- Learning rateê°€ ë„ˆë¬´ ë†’ì„ ë•Œ
- Gradientê°€ í­ë°œí•˜ê±°ë‚˜ ì†Œì‹¤ë  ë•Œ

**ì¦ìƒ:**
```
RuntimeError: Function 'MulBackward0' returned nan values
Loss becomes nan or inf
```

**ì˜ˆë°© ì¡°ì¹˜ (ì´ë¯¸ ì ìš©ë¨):**
```python
# config.py
SELF_TRAIN_LR = 1e-6  # ë§¤ìš° ë‚®ì€ learning rate

# self_training.py
torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
```

**ë°œìƒ ì‹œ ëŒ€ì²˜:**
1. Learning rate ë” ë‚®ì¶”ê¸°: `SELF_TRAIN_LR = 5e-7`
2. Gradient clipping norm ë‚®ì¶”ê¸°: `max_norm=0.5`

---

### 5. Checkpoint ì €ì¥/ë¡œë“œ ì—ëŸ¬

**ë°œìƒ ê°€ëŠ¥ ìƒí™©:**
- Self-training ë„ì¤‘ ëª¨ë¸ ì €ì¥ ì‹œ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±
- Checkpoint í˜•ì‹ ë¶ˆì¼ì¹˜

**ì¦ìƒ:**
```
OSError: [Errno 28] No space left on device
RuntimeError: Error(s) in loading state_dict
```

**ì˜ˆë°© ì¡°ì¹˜:**
- ë””ìŠ¤í¬ ê³µê°„ í™•ì¸:
  ```bash
  df -h /workspace/yongjoo/20252R0136DATA30400/taxoclass/saved_models/
  ```
- ëª¨ë¸ í¬ê¸° í™•ì¸: ~1.3GB per checkpoint

**ë°œìƒ ì‹œ ëŒ€ì²˜:**
1. ì´ì „ checkpoint ì‚­ì œ
2. ì €ì¥ ë¹ˆë„ ì¤„ì´ê¸° (iterationë§ˆë‹¤ë§Œ ì €ì¥)

---

### 6. Multi-label Prediction ê´€ë ¨ ì—ëŸ¬

**ë°œìƒ ê°€ëŠ¥ ìƒí™©:**
- Prediction shapeì´ ì˜ˆìƒê³¼ ë‹¤ë¥¼ ë•Œ
- Target distribution shape mismatch

**ì¦ìƒ:**
```
RuntimeError: The size of tensor a (X) must match the size of tensor b (Y)
IndexError: index X is out of bounds for dimension Y
```

**ì˜ˆë°© ì¡°ì¹˜ (ì½”ë“œ ê²€ì¦):**
```python
# ë°ì´í„° shape í™•ì¸
print(f"Predictions shape: {predictions.shape}")  # Should be (49145, num_classes)
print(f"Target distribution shape: {target_distribution.shape}")
```

**ë°œìƒ ì‹œ ëŒ€ì²˜:**
- `num_classes` ê°’ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
- Hierarchyì—ì„œ ê³„ì‚°ëœ class ìˆ˜ì™€ ëª¨ë¸ì˜ ì¶œë ¥ ì°¨ì› ë¹„êµ

---

### 7. Wandb ë¡œê¹… ì—ëŸ¬

**ë°œìƒ ê°€ëŠ¥ ìƒí™©:**
- Wandb ì¸ì¦ ë§Œë£Œ
- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ

**ì¦ìƒ:**
```
wandb.Error: api_key not configured
requests.exceptions.ConnectionError
```

**ì˜ˆë°© ì¡°ì¹˜:**
```python
# config.pyì—ì„œ wandb ë¹„í™œì„±í™” ê°€ëŠ¥
USE_WANDB = False  # ì—ëŸ¬ ë°œìƒ ì‹œ Falseë¡œ ë³€ê²½
```

**ë°œìƒ ì‹œ ëŒ€ì²˜:**
1. Wandb ë¡œê·¸ì¸ ë‹¤ì‹œ ì‹¤í–‰: `wandb login`
2. ë˜ëŠ” wandb ë¹„í™œì„±í™”í•˜ê³  ê³„ì† ì§„í–‰

---

## ğŸ” ëª¨ë‹ˆí„°ë§ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì‹¤í–‰ ì¤‘ ë‹¤ìŒ ì‚¬í•­ë“¤ì„ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”:

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
```bash
watch -n 1 nvidia-smi
```

### Loss ê°’
- Lossê°€ `nan`ì´ë‚˜ `inf`ê°€ ë˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
- Lossê°€ ë„ˆë¬´ ë¹ ë¥´ê²Œ ì¦ê°€í•˜ë©´ learning rate ì¡°ì • í•„ìš”

### Confidence ë¹„ìœ¨
- Self-training iterationë§ˆë‹¤ ì¶œë ¥ë˜ëŠ” confidence ratio í™•ì¸
- ë„ˆë¬´ ë‚®ìœ¼ë©´ (<10%) threshold ì¡°ì • í•„ìš”

### Disk ê³µê°„
```bash
df -h
```

---

## ğŸ“‹ ê¶Œì¥ ì‹¤í–‰ ìˆœì„œ

1. **ì‹¤í–‰ ì „ í™•ì¸:**
   ```bash
   # GPU ë©”ëª¨ë¦¬ í™•ì¸
   nvidia-smi
   
   # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
   df -h
   
   # í•„ìš”í•œ íŒŒì¼ ì¡´ì¬ í™•ì¸
   ls -lh saved_models/best_model.pt
   ls -lh outputs/similarity_matrix_all.npz
   ls -lh outputs/core_classes.npz
   ```

2. **ì‹¤í–‰:**
   ```bash
   cd /workspace/yongjoo/20252R0136DATA30400/taxoclass
   python main.py
   ```

3. **ì‹¤í–‰ ì¤‘ ëª¨ë‹ˆí„°ë§:**
   - ë³„ë„ í„°ë¯¸ë„ì—ì„œ `watch -n 1 nvidia-smi` ì‹¤í–‰
   - Loss ê°’ì´ ì •ìƒì ìœ¼ë¡œ ê°ì†Œí•˜ëŠ”ì§€ í™•ì¸
   - Confidence ratioê°€ í•©ë¦¬ì ì¸ì§€ í™•ì¸ (20-60% ì •ë„ ì˜ˆìƒ)

4. **ì—ëŸ¬ ë°œìƒ ì‹œ:**
   - ì—ëŸ¬ ë©”ì‹œì§€ ì „ì²´ë¥¼ ë³µì‚¬
   - ìœ„ ì—ëŸ¬ ë¶„ì„ ì„¹ì…˜ì—ì„œ í•´ë‹¹ ì—ëŸ¬ ì°¾ê¸°
   - ì œì•ˆëœ ëŒ€ì²˜ ë°©ë²• ì ìš©

---

## âš™ï¸ ê¸´ê¸‰ ì„¤ì • ì¡°ì •

ë©”ëª¨ë¦¬ë‚˜ ì„±ëŠ¥ ë¬¸ì œ ë°œìƒ ì‹œ `config.py`ì—ì„œ ë‹¤ìŒ ê°’ë“¤ì„ ì¡°ì •:

```python
# ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
BATCH_SIZE = 8  # 16 -> 8
EVAL_BATCH_SIZE = 64  # 128 -> 64

# í•™ìŠµì´ ë¶ˆì•ˆì •í•  ì‹œ
SELF_TRAIN_LR = 5e-7  # 1e-6 -> 5e-7
SELF_TRAIN_THRESHOLD = 0.7  # 0.8 -> 0.7

# í•™ìŠµ ë°ì´í„° ë¶€ì¡± ì‹œ
SELF_TRAIN_THRESHOLD = 0.6  # 0.8 -> 0.6 (ë” ë§ì€ ìƒ˜í”Œ ì‚¬ìš©)

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
SELF_TRAIN_ITERATIONS = 1  # 3 -> 1
SELF_TRAIN_EPOCHS_PER_ITER = 1  # 3 -> 1
```
