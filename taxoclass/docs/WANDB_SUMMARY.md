# Wandb í†µí•© ìš”ì•½

## âœ… **ì™„ë£Œëœ ì‘ì—…**

### **1. Config ì„¤ì • ì¶”ê°€** (`config.py`)

```python
# Weights & Biases (wandb) Settings
USE_WANDB = True
WANDB_PROJECT = "taxoclass-hierarchical"
WANDB_ENTITY = None
WANDB_RUN_NAME = None
WANDB_TAGS = ["hierarchical", "taxonomy", "gnn"]
WANDB_LOG_INTERVAL = 10
WANDB_LOG_GRADIENTS = False
```

---

### **2. Main Pipeline ìˆ˜ì •** (`main.py`)

#### **Wandb ì´ˆê¸°í™”**
- Auto-generated run name: `taxo_bert-large_gnn4_h1024`
- Full config logging (ëª¨ë“  hyperparameters)
- Tags ë° metadata ì¶”ê°€

#### **Stageë³„ ë¡œê¹…**
- **Stage 1**: Similarity í†µê³„ (min, max, mean, std)
- **Stage 2**: Core class í†µê³„ (num, total docs, avg docs)
- **Stage 3**: Label ë¶„í¬, Train/Val samples
- **Final**: Test metrics (accuracy, F1, Top-k)

---

### **3. Classifier Trainer ìˆ˜ì •** (`models/classifier.py`)

#### **ì‹¤ì‹œê°„ ë¡œê¹…**
- Training loss (ë§¤ 10 step)
- Learning rate schedule
- Epochë³„ train/val loss
- Best model update ê¸°ë¡

#### **Global step tracking**
- Continuous step counter
- Epoch êµ¬ë¶„ ê°€ëŠ¥

---

### **4. Self-Trainer ìˆ˜ì •** (`models/self_training.py`)

#### **Iterationë³„ ë¡œê¹…**
- Confident predictions ìˆ˜ ë° ë¹„ìœ¨
- Avg max prediction (confidence)
- Avg target entropy
- Self-training loss per epoch

---

### **5. Requirements ì—…ë°ì´íŠ¸** (`requirements.txt`)

```
wandb>=0.15.0
```

---

### **6. ê°€ì´ë“œ ë¬¸ì„œ ì‘ì„±** (`WANDB_GUIDE.md`)

- ì„¤ì¹˜ ë° ì„¤ì • ë°©ë²•
- ë¡œê¹…ë˜ëŠ” ë©”íŠ¸ë¦­ ìƒì„¸ ì„¤ëª…
- Dashboard í™œìš©ë²•
- Troubleshooting
- Best practices

---

## ğŸ“Š **ë¡œê¹… êµ¬ì¡°**

```
taxoclass-hierarchical (Project)
â”‚
â”œâ”€â”€ stage1/
â”‚   â”œâ”€â”€ similarity_min
â”‚   â”œâ”€â”€ similarity_max
â”‚   â”œâ”€â”€ similarity_mean
â”‚   â””â”€â”€ similarity_std
â”‚
â”œâ”€â”€ stage2/
â”‚   â”œâ”€â”€ num_core_classes
â”‚   â”œâ”€â”€ total_docs_with_core
â”‚   â””â”€â”€ avg_docs_per_core_class
â”‚
â”œâ”€â”€ stage3/
â”‚   â”œâ”€â”€ num_positive_labels
â”‚   â”œâ”€â”€ num_negative_labels
â”‚   â”œâ”€â”€ train_samples
â”‚   â”œâ”€â”€ val_samples
â”‚   â”œâ”€â”€ train_loss (real-time)
â”‚   â”œâ”€â”€ learning_rate (real-time)
â”‚   â”œâ”€â”€ epoch_train_loss
â”‚   â”œâ”€â”€ epoch_val_loss
â”‚   â”œâ”€â”€ best_val_loss
â”‚   â””â”€â”€ best_epoch
â”‚
â”œâ”€â”€ stage4/
â”‚   â”œâ”€â”€ confident_predictions
â”‚   â”œâ”€â”€ confidence_ratio
â”‚   â”œâ”€â”€ avg_max_prediction
â”‚   â”œâ”€â”€ avg_target_entropy
â”‚   â”œâ”€â”€ self_train_loss
â”‚   â””â”€â”€ iteration
â”‚
â””â”€â”€ test/
    â”œâ”€â”€ accuracy
    â”œâ”€â”€ precision
    â”œâ”€â”€ recall
    â”œâ”€â”€ f1_score
    â”œâ”€â”€ top3_accuracy
    â”œâ”€â”€ top5_accuracy
    â”œâ”€â”€ top10_accuracy
    â””â”€â”€ level_*_accuracy
```

---

## ğŸš€ **ì‚¬ìš© ë°©ë²•**

### **Quick Start**

```bash
# 1. wandb ì„¤ì¹˜
pip install wandb

# 2. ë¡œê·¸ì¸
wandb login

# 3. í•™ìŠµ ì‹¤í–‰ (config.pyì—ì„œ USE_WANDB=True)
python main.py

# 4. Dashboard í™•ì¸
# â†’ í„°ë¯¸ë„ì— ì¶œë ¥ëœ URL í´ë¦­
```

### **Wandb ì—†ì´ ì‹¤í–‰**

```python
# config.py
USE_WANDB = False
```

ë˜ëŠ”

```bash
export WANDB_MODE=disabled
python main.py
```

---

## ğŸ’¡ **ì£¼ìš” ê¸°ëŠ¥**

### **1. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**
- Training loss curve
- Validation loss curve
- Learning rate schedule
- Self-training confidence progression

### **2. ì‹¤í—˜ ë¹„êµ**
- ì—¬ëŸ¬ runì„ í•œ ë²ˆì— ë¹„êµ
- Hyperparameter sweep ì§€ì›
- Best model tracking

### **3. ì¬í˜„ ê°€ëŠ¥ì„±**
- ëª¨ë“  config ìë™ ì €ì¥
- Git commit hash ê¸°ë¡ (ì¶”ê°€ ê°€ëŠ¥)
- Random seed ì €ì¥

---

## ğŸ“ˆ **ì˜ˆìƒ íš¨ê³¼**

### **ì‹¤í—˜ ê´€ë¦¬**
- âœ… ì—¬ëŸ¬ ì‹¤í—˜ì„ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬
- âœ… Best model ìë™ ì¶”ì 
- âœ… Hyperparameter ì˜í–¥ ë¶„ì„

### **ë””ë²„ê¹…**
- âœ… Loss curveë¡œ overfitting ê°ì§€
- âœ… Learning rate schedule í™•ì¸
- âœ… Confidence progression ëª¨ë‹ˆí„°ë§

### **ì„±ëŠ¥ ìµœì í™”**
- âœ… Hyperparameter tuning íš¨ìœ¨í™”
- âœ… ì‹¤í—˜ ê²°ê³¼ ì‰¬ìš´ ë¹„êµ
- âœ… Ablation study ìš©ì´

---

## ğŸ”§ **í™•ì¥ ê°€ëŠ¥ì„±**

### **ì¶”ê°€ ê°€ëŠ¥í•œ ë¡œê¹…**

#### **1. Gradient Histograms**
```python
# config.py
WANDB_LOG_GRADIENTS = True

# models/classifier.py
if self.use_wandb and Config.WANDB_LOG_GRADIENTS:
    wandb.watch(self.model, log="all", log_freq=100)
```

#### **2. Model Artifacts**
```python
# main.py
if use_wandb:
    artifact = wandb.Artifact("best_model", type="model")
    artifact.add_file("saved_models/best_model.pt")
    wandb.log_artifact(artifact)
```

#### **3. Prediction Examples**
```python
# main.py
if use_wandb:
    table = wandb.Table(
        columns=["Document", "True", "Predicted", "Correct"],
        data=prediction_examples
    )
    wandb.log({"test/predictions": table})
```

#### **4. Confusion Matrix**
```python
# main.py
if use_wandb:
    wandb.log({
        "test/confusion_matrix": wandb.plot.confusion_matrix(
            y_true=true_labels,
            preds=pred_labels,
            class_names=class_names
        )
    })
```

---

## ğŸ“ **ìˆ˜ì •ëœ íŒŒì¼ ëª©ë¡**

1. âœ… `config.py` - Wandb ì„¤ì • ì¶”ê°€
2. âœ… `main.py` - Wandb ì´ˆê¸°í™” ë° ë¡œê¹…
3. âœ… `models/classifier.py` - Trainer ë¡œê¹…
4. âœ… `models/self_training.py` - Self-trainer ë¡œê¹…
5. âœ… `requirements.txt` - wandb ì¶”ê°€
6. âœ… `WANDB_GUIDE.md` - ìƒì„¸ ê°€ì´ë“œ (36í˜ì´ì§€)
7. âœ… `WANDB_SUMMARY.md` - ìš”ì•½ ë¬¸ì„œ (í˜„ì¬ íŒŒì¼)

---

## ğŸ¯ **í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸**

- [ ] wandb ì„¤ì¹˜ í™•ì¸: `pip list | grep wandb`
- [ ] ë¡œê·¸ì¸ í™•ì¸: `wandb login`
- [ ] í•™ìŠµ ì‹¤í–‰: `python main.py`
- [ ] Wandb run ìƒì„± í™•ì¸
- [ ] Dashboard URL ì ‘ì†
- [ ] Stageë³„ ë©”íŠ¸ë¦­ í™•ì¸
- [ ] Loss curve í™•ì¸
- [ ] Final test metrics í™•ì¸

---

**êµ¬í˜„ ì™„ë£Œ!** ğŸ‰  
ì´ì œ wandbë¥¼ í†µí•´ ì „ì²´ í•™ìŠµ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³ , ì—¬ëŸ¬ ì‹¤í—˜ì„ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

